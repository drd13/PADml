{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phys Astro Data: Deep Learning using Pytorch and Keras\n",
    "\n",
    "Objectives:\n",
    "* Explain the essential components behind training a neural network\n",
    "* Show simple practical example of how to program a neural network\n",
    "* Contrast the two leading frameworks (Pytorch and Keras) so that people can make an informed decision.\n",
    "* Try and make it useful for people who already know machine learning (with small links to papers and asides).\n",
    "\n",
    "We will only talk about neural networks (ie deep learning) as this is what these libraries are specialized for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Basics\n",
    "\n",
    "Machine learning = learning from examples.\n",
    "\n",
    "Let us begin with an example, consider we have a dataset containing images of digits as well as their **labels**, and we want to train a neural network to predict the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png\",width=200,height=200>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png\",width=200,height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want an automated process to design an algorithm, we need to be able to assess whether an algorithm is better than another. This is the **loss function**. A typical choice is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "   MSE = \\sum_{1}^{N} (y_i-\\hat{y}(x_i))^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in finding an algorithm/function that can give a low value of the loss function. We need to have some parametrization for this function. This is where the Neural Network comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*QVIyc5HnGDWTNX3m-nIm9w.png\",width=200,height=200>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*QVIyc5HnGDWTNX3m-nIm9w.png\",width=200,height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **neural network** contains many parameters in the form of edges and activation functions. The activations are defined as\n",
    "$a_j = \\Phi\\left ( \\sum_{i} w_{ij} a_i +b_j \\right )$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By varying the neural network parameters, we change the mathematical function that the neural network is representing. With small changes to the parameters only leading to slight modifications in the function represented by the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look back to what we have done so far, through the neural network, we are able to generate many different algorithms by changing the parameters (weights, activations) and through the loss function we are able to assess which algorithm is the best. At this point, if we had infinite time we could just generate random weights and activations and keep the model that leads to the best loss function. This however, would take a really really really long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation** is what allows us to find good values for the edges and weights of our network. A full explanation is beyond the scope of this talk but we will explain intution behind it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is directly related to the **loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://blog.paperspace.com/content/images/2018/05/challenges-1.png\",width=10,height=10>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://blog.paperspace.com/content/images/2018/05/challenges-1.png\",width=10,height=10>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation** is a way to get the gradient of the loss function, for the current set of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have the gradient of the loss function. We can accordingly make a small change to the parameters accordingly. If we iteratively repeat this procedure, we will then converge to a local minima. This is known as **gradient descent**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*yasmQ5kvlmbYMe8eDkyl6w.png\",width=10,height=10>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*yasmQ5kvlmbYMe8eDkyl6w.png\",width=10,height=10>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For purposes of illustration, we have only shown two dimensions. When we have many parameters, our loss function would have as many dimensions as there are parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize how a neural network is trained:  \n",
    "* Create a Neural network structure and initialize it with random parameter values (weights and activation functions). For our example we want as many inputs as image pixels and as many outputs as digit choices. \n",
    "\n",
    "* Define a loss function which measuring how well our neural network is doing at the task (how well does it predict digits). Before the neural network is trained, the neural network will be terrible at this task.\n",
    "\n",
    "* Iteratively, pass images through the neural network. Estimate the gradient of the parameters and update it. Iteratively improving the neural network output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = torchvision.datasets.MNIST('.', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "\n",
    "class mnistDataset():\n",
    "    __init__():\n",
    "        self.images = os.\n",
    "    __len__():\n",
    "        \n",
    "    __iter__(idx):\n",
    "        \n",
    "        return self.image[i],label[i]\n",
    "\n",
    "data = mnistDataset[0]\n",
    "\n",
    "loader = torch.utils.data.DataLoader(mnist_data\n",
    "  ,  batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at our mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mnist_data[0][0][0].shape\n",
    "for i in range(3):\n",
    "    plt.title(\"label:{}\".format(mnist_data[i][1].numpy()))\n",
    "    plt.imshow(mnist_data[i][0][0], cmap='gray', interpolation='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pytorch, we define our neural network by inheriting from nn.module. The forward function is the function that is called when evaluating new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistNetwork, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(N_V, 1024),\n",
    "                                nn.LeakyReLU(),                             \n",
    "                                nn.Linear(1024,512),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Linear(512,256),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Linear(256,256),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Linear(256,128),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Linear(128,128),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Linear(128,64),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Linear(64, N_U)\n",
    "                                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = MnistNetwork()\n",
    "out = network(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we next need to define a loss function, and choose which flavour of gradient descent to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-4feadab0ffd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create a stochastic gradient descent optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# create a loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optim' is not defined"
     ]
    }
   ],
   "source": [
    "# create a stochastic gradient descent optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# create a loss function\n",
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in loader(dataset):\n",
    "    optimizer.zero_grad()\n",
    "    out = network(x_in)\n",
    "    out2 = netwowrk2(x_in2)\n",
    "    loss1(out,pred)\n",
    "    loss\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Neural Networks?\n",
    "\n",
    "Neural network are very flexible function estimators that learn through being shown \"examples\". Compared to other techniques, a strength of Neural Networks is that they can be customized to fit the structure of a dataset (Convolutional Neural Networks for images, Recurrent Neural Networks for time-series). Another advantage is that once trained, they can yield very quick predictions.\n",
    "\n",
    "Unlike other algorithms like Support Vector Machines or Linear Regression, the loss function they minimize is not convex (ie it does not have a single minimum). Instead it has multiple minimums, and in training we are interested in finding a suitably good minimum (as opposed to a global minimum). This means that their training can sometimes be a lot more fiddly. The loss function that you minimize can also be modified to fit the task you are trying to accomplish (see VAE or GAN for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is actually an interesting debate going on about whether deep learning methods should be assumption driven or whether they should be fully black-box methods. (see this open letter by max welling for example https://staff.fnwi.uva.nl/m.welling/wp-content/uploads/Model-versus-Data-AI-1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Basics\n",
    "\n",
    "Understanding how a neural network is trained requires understanding alot of moving parts here we will give a brief explanation of all the moving parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are just mathematical functions approximators. By changing the weights (values associated with the edges) and activati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*QVIyc5HnGDWTNX3m-nIm9w.png\",width=200,height=200>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*QVIyc5HnGDWTNX3m-nIm9w.png\",width=200,height=200>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png\",width=200,height=200>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png\",width=200,height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By varying the neural network parameters, we change the mathematical function that the neural network is representing. With small changes only slightly changing the output of the neural network.\n",
    "\n",
    "The way we would do this with a neural network would be to:\n",
    "* Create a Neural network structure and initialize it with random parameter values (weights and activation functions). For our example we want as many inputs as image pixels and as many outputs as digit choices. \n",
    "\n",
    "* Define a loss function which measuring how well our neural network is doing at the task (how well does it predict digits). Before the neural network is trained, the output of the neural network will be terrible.\n",
    "\n",
    "* Iteratively, pass images through the neural network.\n",
    "\n",
    "\n",
    "\n",
    "The aim of deep learning is, through an iterative procedure, to find a set of parameters that yield a good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*QVIyc5HnGDWTNX3m-nIm9w.png\",width=200,height=200>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*QVIyc5HnGDWTNX3m-nIm9w.png\",width=200,height=200>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://blog.paperspace.com/content/images/2018/05/challenges-1.png\",width=10,height=10>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://blog.paperspace.com/content/images/2018/05/challenges-1.png\",width=10,height=10>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This picture shows the loss function with only 2 parameters. As always our intuition breaks down, neural networks will usually have tens of thousands of parameters. A minima will then only occur when all dimenions are at a minimum (otherwise saddle point). As such, its alot harder to reach a local minima. This is the same type of insight as the lottery ticket paper (see link). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
