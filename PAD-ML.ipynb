{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phys Astro Data: Deep Learning using Pytorch and Keras\n",
    "\n",
    "Objectives:\n",
    "* Explain the essential components behind training a neural network\n",
    "* Show simple practical example of how to program a neural network\n",
    "* Contrast the two leading frameworks (Pytorch and Keras) so that people can make an informed decision.\n",
    "* Try and make it useful for people who already know machine learning (with small links to papers and asides).\n",
    "\n",
    "We will only talk about neural networks (ie deep learning) as this is what these libraries are specialized for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Basics\n",
    "\n",
    "Machine learning = learning from examples.\n",
    "\n",
    "Let us begin with an example, consider we have a dataset containing images of digits as well as their **labels**, and we want to be able to predict the labels directly from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png\",width=200,height=200>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png\",width=200,height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want an automated process to design an algorithm, we need to be able to assess whether an algorithm is better than another. This is where the **loss function** comes in. A typical choice is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "   MSE = \\sum_{1}^{N} (y_i-\\hat{y}(x_i))^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "Cross Entropy := -  \\sum_{1}^{N} \\sum_{c=1}^My_{o,c}\\log(p_{o,c})\n",
    "\\end{equation}\n",
    "where \n",
    "* M - number of classes (0,1,2,3,4,5,6,7,8,9 for the digit recognition)\n",
    "* y - binary indicator (0 or 1) if class label c is the correct classification for observation o\n",
    "* p - predicted probability observation o is of class c. \n",
    "\n",
    "This will be maximized when $p$ is exactly equal to the corresponding y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in finding an algorithm/function that can find a low value of the loss function. We need to have some flexible way of parametrizing this function. This is where the Neural Network comes in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/1600/1*QVIyc5HnGDWTNX3m-nIm9w.png\",width=200,height=200>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*QVIyc5HnGDWTNX3m-nIm9w.png\",width=200,height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **neural network** contains many parameters in the form of edges and activation functions. The activations are defined as\n",
    "$a_j = \\Phi\\left ( \\sum_{i} w_{ij} a_i +b_j \\right )$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By varying the neural network parameters, we change the mathematical function that the neural network is representing. With small changes to the parameters only leading to slight modifications in the function represented by the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look back to what we have done so far, through the neural network, we are able to generate many different algorithms by changing the parameters (weights, activations) and through the loss function we are able to assess which algorithm is the best. At this point, if we had infinite time we could just generate random weights and activations and keep the model that leads to the best loss function. This however, would take a really really really long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation** is what allows us to find good values for the edges and weights of our network. A full explanation is beyond the scope of this talk but we will explain intution behind it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is directly related to the **loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://blog.paperspace.com/content/images/2018/05/challenges-1.png\",width=10,height=10>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://blog.paperspace.com/content/images/2018/05/challenges-1.png\",width=10,height=10>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation** is a way to get the gradient of the loss function, for the current set of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have the gradient of the loss function. We can make small changes to the parameters accordingly. If we iteratively repeat this procedure, we will then converge to a local minima. This is known as **gradient descent**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*yasmQ5kvlmbYMe8eDkyl6w.png\",width=10,height=10>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*yasmQ5kvlmbYMe8eDkyl6w.png\",width=10,height=10>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For purposes of illustration, we have only shown two dimensions. When we have many parameters, our loss function would have as many dimensions as there are parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize how a neural network is trained:  \n",
    "* Create a Neural network structure and initialize it with random parameter values (weights and activation functions). For our example we want as many inputs as image pixels and as many outputs as digit choices. \n",
    "\n",
    "* Define a loss function which measuring how well our neural network is doing at the task (how well does it predict digits). Before the neural network is trained, the neural network will be terrible at this task.\n",
    "\n",
    "* Iteratively, pass images through the neural network. Estimate the gradient of the parameters and update it. Iteratively improving the neural network output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameters\n",
    "Hyperparameters are values/parameters set by the user before the learning begins, in a way similar to the input parameters for our physical models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_batch = 64\n",
    "n_batch_test = 1000\n",
    "n_classes = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mnist = torchvision.datasets.MNIST('.', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "test_mnist = torchvision.datasets.MNIST('.', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "\n",
    "\n",
    "loader = torch.utils.data.DataLoader(train_mnist,batch_size=n_batch, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_mnist,batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at our mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_mnist[0][0][0].shape\n",
    "for i in range(3):\n",
    "    plt.title(\"label:{}\".format(train_mnist[i][1].numpy()))\n",
    "    plt.imshow(train_mnist[i][0][0], cmap='gray', interpolation='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pytorch, we define our neural network by inheriting from nn.module. The forward function is the function that is called when evaluating new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  0.2249,  1.5996,  2.7960,  1.5996,  0.2122, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.1867,  2.6051,  2.7833,  2.7833,  2.7833,  2.5924, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.2631,\n",
       "           2.4651,  2.7960,  2.7833,  2.6178,  2.5415,  2.7833,  0.3013,\n",
       "          -0.3478, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.2969,  0.3395,  2.4269,\n",
       "           2.7833,  2.7960,  2.7833,  2.1469,  0.6450,  2.7833,  2.7960,\n",
       "           1.1286, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242,  1.6505,  2.7833,  2.7833,\n",
       "           2.7833,  2.7960,  2.7833,  2.7833,  0.7977,  1.9814,  2.7960,\n",
       "           1.7014, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242,  0.2249,  2.6051,  2.7960,  2.7960,\n",
       "           1.9942,  1.0268,  2.7960,  2.4778,  0.1740,  0.5813,  2.8215,\n",
       "           1.7141, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242,  0.1867,  2.6051,  2.7833,  2.7833,  1.8541,\n",
       "          -0.2715,  0.5304,  1.1159, -0.1569, -0.4242, -0.4242,  2.7960,\n",
       "           2.6687,  0.2122, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  0.0595,  1.6759,  2.7960,  2.5415,  2.2233,  0.6450,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.7960,\n",
       "           2.7833,  1.6759, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.3351,  1.8414,  2.7833,  2.6306,  0.4795, -0.1824, -0.0678,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.7960,\n",
       "           2.7833,  2.0578, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.3013,  2.7833,  2.7833,  0.3777, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.7960,\n",
       "           2.7833,  2.0578, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           2.0960,  2.7960,  1.9942, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.8215,\n",
       "           2.7960,  2.0705, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.5431,\n",
       "           2.7069,  2.7833,  1.0013, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  2.7960,\n",
       "           2.7833,  1.4596, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6577,\n",
       "           2.7833,  2.5033, -0.1060, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.3351,  1.2941,  2.7960,\n",
       "           1.9432, -0.2715, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6577,\n",
       "           2.7833,  2.4142, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.3351,  1.2432,  2.7833,  2.4396,\n",
       "           0.4795, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6577,\n",
       "           2.7833,  1.4214, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242,  0.1867,  1.6759,  2.7833,  1.7778, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6704,\n",
       "           2.7960,  2.4396, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  1.0268,  2.6051,  2.7960,  1.6378, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6577,\n",
       "           2.7833,  2.7451,  1.4341,  0.1867, -0.0551,  0.6577,  1.8414,\n",
       "           2.4396,  2.7960,  2.4142,  1.7014,  0.2886, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6577,\n",
       "           2.7833,  2.7833,  2.7833,  2.4906,  2.3124,  2.7833,  2.7833,\n",
       "           2.7833,  2.0705,  1.2305, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.0678,\n",
       "           2.1087,  2.7833,  2.7833,  2.7960,  2.7833,  2.7833,  2.5415,\n",
       "           1.4214, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.1060,  1.2050,  2.7833,  2.7960,  2.7833,  1.3705,  0.0467,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mnist[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistNetwork, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(28*28, 1024),\n",
    "                                nn.ReLU(), \n",
    "                                nn.Linear(1024, 512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512,256),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(256,128),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(128, 10)\n",
    "                                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "        #return F.softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = MnistNetwork()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we next need to define a loss function, and choose which flavour of gradient descent to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a stochastic gradient descent optimizer\n",
    "optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
    "# create a loss function\n",
    "loss =  nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next train the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is:0.3699260950088501\n",
      "the loss is:0.2301604002714157\n",
      "the loss is:0.3370080590248108\n",
      "the loss is:0.49084287881851196\n",
      "the loss is:0.29286646842956543\n",
      "the loss is:0.630861759185791\n",
      "the loss is:0.47106826305389404\n",
      "the loss is:0.5762180089950562\n",
      "the loss is:0.4466243088245392\n",
      "the loss is:0.26295390725135803\n",
      "the loss is:0.12444741278886795\n",
      "the loss is:0.10392271727323532\n",
      "the loss is:0.23963172733783722\n",
      "the loss is:0.45624658465385437\n",
      "the loss is:0.18829910457134247\n",
      "the loss is:0.22249044477939606\n",
      "the loss is:0.43657487630844116\n",
      "the loss is:0.15464496612548828\n",
      "the loss is:0.28085482120513916\n",
      "the loss is:0.21797719597816467\n",
      "the loss is:0.0799853503704071\n",
      "the loss is:0.25625231862068176\n",
      "the loss is:0.16097410023212433\n",
      "the loss is:0.1941976696252823\n",
      "the loss is:0.3433259129524231\n",
      "the loss is:0.2217121720314026\n",
      "the loss is:0.21005691587924957\n",
      "the loss is:0.34178924560546875\n",
      "the loss is:0.4763568043708801\n",
      "the loss is:0.41333457827568054\n",
      "the loss is:0.2139786183834076\n",
      "the loss is:0.3510662019252777\n",
      "the loss is:0.4116656482219696\n",
      "the loss is:0.18206430971622467\n",
      "the loss is:0.1836923211812973\n",
      "the loss is:0.1355668604373932\n",
      "the loss is:0.11143196374177933\n",
      "the loss is:0.5381934642791748\n",
      "the loss is:0.06965046375989914\n",
      "the loss is:0.5130887627601624\n",
      "the loss is:0.46209004521369934\n",
      "the loss is:0.09024276584386826\n",
      "the loss is:0.3050321340560913\n",
      "the loss is:0.3660404086112976\n",
      "the loss is:0.1684686541557312\n",
      "the loss is:0.6784517168998718\n",
      "the loss is:0.13390013575553894\n",
      "the loss is:0.31981584429740906\n",
      "the loss is:0.33234792947769165\n",
      "the loss is:0.2003428190946579\n",
      "the loss is:0.31980788707733154\n",
      "the loss is:0.15384016931056976\n",
      "the loss is:0.2469722330570221\n",
      "the loss is:0.19519665837287903\n",
      "the loss is:0.10472454130649567\n",
      "the loss is:0.14538629353046417\n",
      "the loss is:0.14361169934272766\n",
      "the loss is:0.44486328959465027\n",
      "the loss is:0.23385372757911682\n",
      "the loss is:0.47183895111083984\n",
      "the loss is:0.03825639188289642\n",
      "the loss is:0.26048463582992554\n",
      "the loss is:0.4460740089416504\n",
      "the loss is:0.34284594655036926\n",
      "the loss is:0.2500571608543396\n",
      "the loss is:0.27533262968063354\n",
      "the loss is:0.11037769913673401\n",
      "the loss is:0.07800483703613281\n",
      "the loss is:0.3284018337726593\n",
      "the loss is:0.5345223546028137\n",
      "the loss is:0.29410848021507263\n",
      "the loss is:0.2612317204475403\n",
      "the loss is:0.1699923276901245\n",
      "the loss is:0.17306023836135864\n",
      "the loss is:0.31974124908447266\n",
      "the loss is:0.37429988384246826\n",
      "the loss is:0.29310011863708496\n",
      "the loss is:0.35029923915863037\n",
      "the loss is:0.24208998680114746\n",
      "the loss is:0.28159788250923157\n",
      "the loss is:0.1315126270055771\n",
      "the loss is:0.3039780557155609\n",
      "the loss is:0.1508055329322815\n",
      "the loss is:0.2465711236000061\n",
      "the loss is:0.24150076508522034\n",
      "the loss is:0.3364316523075104\n",
      "the loss is:0.37107494473457336\n",
      "the loss is:0.32182741165161133\n",
      "the loss is:0.2947370409965515\n",
      "the loss is:0.0905102863907814\n",
      "the loss is:0.21848580241203308\n",
      "the loss is:0.14810802042484283\n",
      "the loss is:0.1948350965976715\n",
      "the loss is:0.12305936962366104\n",
      "the loss is:0.2841607630252838\n",
      "the loss is:0.15203499794006348\n",
      "the loss is:0.044877052307128906\n",
      "the loss is:0.5227827429771423\n",
      "the loss is:0.20285820960998535\n",
      "the loss is:0.07035373896360397\n",
      "the loss is:0.32714807987213135\n",
      "the loss is:0.502962589263916\n",
      "the loss is:0.06023984029889107\n",
      "the loss is:0.4838045835494995\n",
      "the loss is:0.12232828140258789\n",
      "the loss is:0.42306196689605713\n",
      "the loss is:0.16066062450408936\n",
      "the loss is:0.281846821308136\n",
      "the loss is:0.15944458544254303\n",
      "the loss is:0.17137493193149567\n",
      "the loss is:0.17265868186950684\n",
      "the loss is:0.27024203538894653\n",
      "the loss is:0.14852222800254822\n",
      "the loss is:0.17828041315078735\n",
      "the loss is:0.14334696531295776\n",
      "the loss is:0.20351047813892365\n",
      "the loss is:0.10185067355632782\n",
      "the loss is:0.07731454074382782\n",
      "the loss is:0.08823501318693161\n",
      "the loss is:0.2670544385910034\n",
      "the loss is:0.37834879755973816\n",
      "the loss is:0.2215518057346344\n",
      "the loss is:0.4071730375289917\n",
      "the loss is:0.3531497120857239\n",
      "the loss is:0.04106846824288368\n",
      "the loss is:0.19911503791809082\n",
      "the loss is:0.15317969024181366\n",
      "the loss is:0.16640987992286682\n",
      "the loss is:0.21014021337032318\n",
      "the loss is:0.3684879541397095\n",
      "the loss is:0.15803013741970062\n",
      "the loss is:0.2523956298828125\n",
      "the loss is:0.3111881613731384\n",
      "the loss is:0.069743812084198\n",
      "the loss is:0.2531680166721344\n",
      "the loss is:0.14820297062397003\n",
      "the loss is:0.26584044098854065\n",
      "the loss is:0.31821757555007935\n",
      "the loss is:0.4040880799293518\n",
      "the loss is:0.24621739983558655\n",
      "the loss is:0.3285800516605377\n",
      "the loss is:0.19351521134376526\n",
      "the loss is:0.0705464631319046\n",
      "the loss is:0.34471166133880615\n",
      "the loss is:0.10142591595649719\n",
      "the loss is:0.20132990181446075\n",
      "the loss is:0.5753543376922607\n",
      "the loss is:0.5252929925918579\n",
      "the loss is:0.19356326758861542\n",
      "the loss is:0.20886211097240448\n",
      "the loss is:0.1995714008808136\n",
      "the loss is:0.1047489196062088\n",
      "the loss is:0.6555320024490356\n",
      "the loss is:0.19817708432674408\n",
      "the loss is:0.31028443574905396\n",
      "the loss is:0.11499317735433578\n",
      "the loss is:0.2466900497674942\n",
      "the loss is:0.3669425845146179\n",
      "the loss is:0.12163283675909042\n",
      "the loss is:0.22168633341789246\n",
      "the loss is:0.18115393817424774\n",
      "the loss is:0.22965802252292633\n",
      "the loss is:0.29406169056892395\n",
      "the loss is:0.4479718804359436\n",
      "the loss is:0.2582440972328186\n",
      "the loss is:0.34123751521110535\n",
      "the loss is:0.46875667572021484\n",
      "the loss is:0.220691978931427\n",
      "the loss is:0.1990801841020584\n",
      "the loss is:0.2732868492603302\n",
      "the loss is:0.2881728410720825\n",
      "the loss is:0.16869746148586273\n",
      "the loss is:0.08650770038366318\n",
      "the loss is:0.24079276621341705\n",
      "the loss is:0.15475942194461823\n",
      "the loss is:0.14851388335227966\n",
      "the loss is:0.08370693027973175\n",
      "the loss is:0.27691566944122314\n",
      "the loss is:0.36089473962783813\n",
      "the loss is:0.08703946322202682\n",
      "the loss is:0.17755955457687378\n",
      "the loss is:0.3126164376735687\n",
      "the loss is:0.1903596818447113\n",
      "the loss is:0.20538131892681122\n",
      "the loss is:0.10827816277742386\n",
      "the loss is:0.10058043152093887\n",
      "the loss is:0.3827430009841919\n",
      "the loss is:0.057173699140548706\n",
      "the loss is:0.1832142472267151\n",
      "the loss is:0.2533166706562042\n",
      "the loss is:0.21350954473018646\n",
      "the loss is:0.06340566277503967\n",
      "the loss is:0.15491287410259247\n",
      "the loss is:0.3490491211414337\n",
      "the loss is:0.28081968426704407\n",
      "the loss is:0.44167831540107727\n",
      "the loss is:0.10120408982038498\n",
      "the loss is:0.21997348964214325\n",
      "the loss is:0.17061372101306915\n",
      "the loss is:0.1260710209608078\n",
      "the loss is:0.09237945824861526\n",
      "the loss is:0.0323810912668705\n",
      "the loss is:0.27682700753211975\n",
      "the loss is:0.49692046642303467\n",
      "the loss is:0.1363077014684677\n",
      "the loss is:0.336731880903244\n",
      "the loss is:0.40742844343185425\n",
      "the loss is:0.6256254315376282\n",
      "the loss is:0.10503672063350677\n",
      "the loss is:0.40023866295814514\n",
      "the loss is:0.29396969079971313\n",
      "the loss is:0.3251659870147705\n",
      "the loss is:0.4372650682926178\n",
      "the loss is:0.33689045906066895\n",
      "the loss is:0.2819274663925171\n",
      "the loss is:0.31245341897010803\n",
      "the loss is:0.30132049322128296\n",
      "the loss is:0.25261425971984863\n",
      "the loss is:0.36788201332092285\n",
      "the loss is:0.22644636034965515\n",
      "the loss is:0.46890848875045776\n",
      "the loss is:0.31205812096595764\n",
      "the loss is:0.22213402390480042\n",
      "the loss is:0.33276548981666565\n",
      "the loss is:0.3205713927745819\n",
      "the loss is:0.23691563308238983\n",
      "the loss is:0.11675450205802917\n",
      "the loss is:0.13009695708751678\n",
      "the loss is:0.2117406576871872\n",
      "the loss is:0.3378334045410156\n",
      "the loss is:0.1040680855512619\n",
      "the loss is:0.24564890563488007\n",
      "the loss is:0.22763974964618683\n",
      "the loss is:0.2317449003458023\n",
      "the loss is:0.3565477728843689\n",
      "the loss is:0.21242891252040863\n",
      "the loss is:0.2463403344154358\n",
      "the loss is:0.10294186323881149\n",
      "the loss is:0.15456092357635498\n",
      "the loss is:0.6132043600082397\n",
      "the loss is:0.3435268700122833\n",
      "the loss is:0.32224422693252563\n",
      "the loss is:0.592927873134613\n",
      "the loss is:0.24595719575881958\n",
      "the loss is:0.2833307087421417\n",
      "the loss is:0.3071783185005188\n",
      "the loss is:0.3735928535461426\n",
      "the loss is:0.19025515019893646\n",
      "the loss is:0.34507307410240173\n",
      "the loss is:0.30730754137039185\n",
      "the loss is:0.294888436794281\n",
      "the loss is:0.12168582528829575\n",
      "the loss is:0.1700109988451004\n",
      "the loss is:0.3442007303237915\n",
      "the loss is:0.10092093795537949\n",
      "the loss is:0.14220373332500458\n",
      "the loss is:0.2544115483760834\n",
      "the loss is:0.25616255402565\n",
      "the loss is:0.17798419296741486\n",
      "the loss is:0.21087448298931122\n",
      "the loss is:0.27561065554618835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is:0.1972634345293045\n",
      "the loss is:0.3355351388454437\n",
      "the loss is:0.12442783266305923\n",
      "the loss is:0.4616653025150299\n",
      "the loss is:0.2197376936674118\n",
      "the loss is:0.45715001225471497\n",
      "the loss is:0.13884387910366058\n",
      "the loss is:0.24229539930820465\n",
      "the loss is:0.2864378094673157\n",
      "the loss is:0.3195268511772156\n",
      "the loss is:0.555370032787323\n",
      "the loss is:0.2786458134651184\n",
      "the loss is:0.25787436962127686\n",
      "the loss is:0.19152423739433289\n",
      "the loss is:0.30374783277511597\n",
      "the loss is:0.17759986221790314\n",
      "the loss is:0.13737301528453827\n",
      "the loss is:0.39483246207237244\n",
      "the loss is:0.15692967176437378\n",
      "the loss is:0.16546779870986938\n",
      "the loss is:0.29328426718711853\n",
      "the loss is:0.2045619934797287\n",
      "the loss is:0.2658282220363617\n",
      "the loss is:0.2277069240808487\n",
      "the loss is:0.22470666468143463\n",
      "the loss is:0.2882230281829834\n",
      "the loss is:0.2609866261482239\n",
      "the loss is:0.16175656020641327\n",
      "the loss is:0.13287511467933655\n",
      "the loss is:0.4907761514186859\n",
      "the loss is:0.3190431296825409\n",
      "the loss is:0.39045166969299316\n",
      "the loss is:0.20802530646324158\n",
      "the loss is:0.2289460301399231\n",
      "the loss is:0.3468063175678253\n",
      "the loss is:0.09812745451927185\n",
      "the loss is:0.7259835004806519\n",
      "the loss is:0.21236677467823029\n",
      "the loss is:0.487559050321579\n",
      "the loss is:0.22838355600833893\n",
      "the loss is:0.48361000418663025\n",
      "the loss is:0.11851751059293747\n",
      "the loss is:0.07540427893400192\n",
      "the loss is:0.33369097113609314\n",
      "the loss is:0.2831569015979767\n",
      "the loss is:0.22794732451438904\n",
      "the loss is:0.126207634806633\n",
      "the loss is:0.18729965388774872\n",
      "the loss is:0.2574557363986969\n",
      "the loss is:0.23940961062908173\n",
      "the loss is:0.3496093451976776\n",
      "the loss is:0.1300191879272461\n",
      "the loss is:0.5130670666694641\n",
      "the loss is:0.21020331978797913\n",
      "the loss is:0.0786433070898056\n",
      "the loss is:0.39934977889060974\n",
      "the loss is:0.5081226229667664\n",
      "the loss is:0.33212170004844666\n",
      "the loss is:0.22755716741085052\n",
      "the loss is:0.21386925876140594\n",
      "the loss is:0.07215731590986252\n",
      "the loss is:0.19716179370880127\n",
      "the loss is:0.4491100609302521\n",
      "the loss is:0.20565861463546753\n",
      "the loss is:0.2905500829219818\n",
      "the loss is:0.19867341220378876\n",
      "the loss is:0.29243865609169006\n",
      "the loss is:0.2447052150964737\n",
      "the loss is:0.338741272687912\n",
      "the loss is:0.07749967277050018\n",
      "the loss is:0.5082252621650696\n",
      "the loss is:0.5103037357330322\n",
      "the loss is:0.2378586381673813\n",
      "the loss is:0.2110110968351364\n",
      "the loss is:0.20556318759918213\n",
      "the loss is:0.25091904401779175\n",
      "the loss is:0.48710954189300537\n",
      "the loss is:0.5151504874229431\n",
      "the loss is:0.1992066502571106\n",
      "the loss is:0.20114560425281525\n",
      "the loss is:0.5357010364532471\n",
      "the loss is:0.11257798969745636\n",
      "the loss is:0.14392586052417755\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8562a337c832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the loss is:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#update the weights in accordance with the backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(epochs):\n",
    "    for i,(data,label) in enumerate(loader):\n",
    "        #set the gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "        #reshape data\n",
    "        data = data.view(n_batch,28*28)\n",
    "        #predict the labels for the inputs\n",
    "        pred_label = network(data)\n",
    "        #calculate the loss between the predicted and true labels\n",
    "        err =  loss(pred_label,label)\n",
    "        #backpropagate to get the derivatives\n",
    "        err.backward()\n",
    "        print(\"the loss is:{}\".format(err))\n",
    "        #update the weights in accordance with the backpropagation\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.937\n",
      "0.935\n",
      "0.931\n",
      "0.933\n",
      "0.943\n",
      "0.931\n",
      "0.916\n",
      "0.938\n",
      "0.93\n",
      "0.943\n"
     ]
    }
   ],
   "source": [
    "for i,(data,label) in enumerate(test_loader):\n",
    "    data = data.view(n_batch_test,28*28)\n",
    "    pred = network(data)\n",
    "    pred_labels = torch.argmax(pred,1)\n",
    "    a = pred_labels == label\n",
    "    print(torch.sum(a).numpy()/n_batch_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras is a high level API used to construct different neural networks. Users are allowed to use different deep learning libaraies as backend (The actual code that runs the model and computation), such as TensorFlow, CNTK, or Theano.  It is a more straight-forward and user friendly API compared to Tensorflow (without the sessions, placeholder etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset\n",
    "The dataset we are going to use today , MNIST, is one of the standard dataset commonly used for branchmarking, and thus Keras has created dedicated classes to import these standard datasets. \n",
    "There are other commonly used datasets, you can find them here:https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras has made it into a class\n",
    "from keras.datasets import mnist\n",
    "## separate data into training set and test set.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (60000, 28, 28) Training Label: (60000,)\n",
      "Test set: (10000, 28, 28) Test Label: (10000,)\n"
     ]
    }
   ],
   "source": [
    "#lets inspect the shape of each component:\n",
    "print(\"Training set:\",x_train.shape,\"Training Label:\",y_train.shape)\n",
    "print(\"Test set:\",x_test.shape,\"Test Label:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of each train and test set tells us how many 28x28 images are used for training and test, each images will have their own corresponding *labels*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise the data\n",
    "Neural Network works better when the data is normalised. The idea is to put every features (input data into a common scale). It is especially important when the input data has different ranges of values. There are two main reasons for this technique:\n",
    "1. Un-normalised data will cause the gradient to oscillate back and forth, and the neural network will end up taking longer time to complete the training\n",
    "The power of neural network relies on its ability to adjust weights, such that it can get closer to the optimum vlaue. The gradient computed at each iteration served as a guiding light for the Neural Network, so that it knows which direction it should move in order to get to the global max/min.\n",
    "2. Features with higher range (such as income as compared to age), will dominate the learning as it will have the highest variation when we change the weight. Normalising the features can put every features on the same ground and thus each of them will be considered equally.\n",
    "\n",
    "One of the most common normalisation techniques is to normalise the feature range to [0,1]. \n",
    "$$y = \\frac{x - x_{min}}{x_{max}-x_{min}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - x_train.min())/(x_train.max() - x_train.min())\n",
    "x_test = (x_test - x_test.min())/(x_test.max() - x_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0, 1.0, 0.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the maximum and minimum:\n",
    "x_train.max(),x_train.min(),x_test.max(),x_test.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataformat for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28*28)\n",
    "x_test = x_test.reshape(10000, 28*28)\n",
    "## turn them into one-hot vector\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "#further divides training data into training and validation data\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28,28))\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr = learning_rate ),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 29s 543us/step - loss: 0.3271 - acc: 0.9109 - val_loss: 0.1860 - val_acc: 0.9498\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 29s 529us/step - loss: 0.1935 - acc: 0.9502 - val_loss: 0.1821 - val_acc: 0.9578\n",
      "Epoch 3/5\n",
      "17984/54000 [========>.....................] - ETA: 19s - loss: 0.1663 - acc: 0.9576"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-8af1ef9eb1d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                      validation_data=(X_val, Y_val), shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,batch_size=n_batch,\n",
    "                                     epochs=epochs,\n",
    "                                     verbose=1,\n",
    "                                     validation_data=(X_val, Y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2177767854694277\n",
      "Test accuracy: 0.9455\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "In the last section we have used Tensorboard to look at some simple computation graph. Keras provided a simple functionality to incorporate our model into Tensorboard. It can be used to monitor the training process, the entire architecture of the deep learning model and their associated weights, and many more: check out this link:\n",
    "https://keras.io/callbacks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-9ce093c65c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                          \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                          \u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                          write_images=False,update_freq='epoch',batch_size=n_batch)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m history = model.fit(X_train,Y_train,batch_size=n_batch,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_dir, histogram_freq, batch_size, write_graph, write_grads, write_images, embeddings_freq, embeddings_layer_names, embeddings_metadata, embeddings_data, update_freq)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprojector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             raise ImportError('You need the TensorFlow module installed to '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfactorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distributions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoftplus_inverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtridiag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf_normal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/distributions/python/ops/estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_compute_weighted_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_RegressionHead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlearn_io\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProblemType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDNNClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDNNEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDNNRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetric_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdnn_linear_combined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhead_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetric_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhead_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_feeder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaved_model_export_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdask_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_dask_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdask_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_dask_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdask_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHAS_DASK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m   \u001b[0mallowed_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mHAS_DASK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/dask/dataframe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m from .core import (DataFrame, Series, Index, _Frame, map_partitions,\n\u001b[0m\u001b[1;32m      4\u001b[0m                    repartition, to_delayed, to_datetime, to_timedelta)\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mCache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/dask/array/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwrap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcreation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mones_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mempty_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrechunk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrechunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## initialise tensorboard call back object\n",
    "csvlogger = keras.callbacks.CSVLogger(\"./Graph/training_log.csv\", separator=',', append=False)\n",
    "\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', \n",
    "                                         histogram_freq=1, \n",
    "                                         write_graph=True, \n",
    "                                         write_images=False,update_freq='epoch',batch_size=n_batch)\n",
    "\n",
    "history = model.fit(X_train,Y_train,batch_size=n_batch,\n",
    "                                     epochs=epochs,\n",
    "                                     verbose=1,\n",
    "                                     validation_data=(X_val, Y_val), shuffle=True,callbacks=[tbCallBack,csvlogger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about Tensorflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We have been talking about PyTorch, Keras etc, but where is Tensorflow ?\n",
    "Tensorflow implementation is actually less straight forward. As you have seen in the previous seminar, to run a deep learning model we will need to the following:\n",
    "1. Define the variables (placeholders) for any input to the computational graph\n",
    "2. Define the computational graph ( in this case, our deep learning model)\n",
    "3. Define the loss function and optimizer\n",
    "4. Start a session and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "## Tensorflow has also created a module for MNIST dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-ce28c7c86e34>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/gordonyip/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/gordonyip/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/gordonyip/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/gordonyip/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/gordonyip/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "## load the data, set one hot to True, similar to what we did in keras.utils.to_categorical\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of nodes for different hidden layers\n",
    "n_nodes_hl1 = 1024\n",
    "n_nodes_hl2 = 512\n",
    "n_nodes_hl3 = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define our variables. 784 is the flatten version of the 28x28 image\n",
    "input_data = tf.placeholder('float', [None, 28*28])\n",
    "target = tf.placeholder('float')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    #initialise weights for different hidden layers\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([28*28, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes])),}\n",
    "\n",
    "\n",
    "    layer1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    layer1 = tf.nn.relu(layer1)\n",
    "\n",
    "    layer2 = tf.add(tf.matmul(layer1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "\n",
    "    layer3 = tf.add(tf.matmul(layer2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    layer3 = tf.nn.relu(layer3)\n",
    "\n",
    "    output = tf.matmul(layer3,output_layer['weights']) + output_layer['biases']\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 5 loss: 1357915.1335601807\n",
      "Epoch 1 completed out of 5 loss: 280879.22898864746\n",
      "Epoch 2 completed out of 5 loss: 141985.88475704193\n",
      "Epoch 3 completed out of 5 loss: 80733.3616547263\n",
      "Epoch 4 completed out of 5 loss: 51478.91358392696\n",
      "Accuracy: 0.9469\n"
     ]
    }
   ],
   "source": [
    "prediction = neural_network_model(input_data)\n",
    "# OLD VERSION:\n",
    "#cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(prediction,y) )\n",
    "# NEW:\n",
    "cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=target) )\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # OLD:\n",
    "    #sess.run(tf.initialize_all_variables())\n",
    "    # NEW:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ## epochs, number of times NN will see the data\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for _ in range(int(mnist.train.num_examples/n_batch)):\n",
    "            epoch_x, epoch_y = mnist.train.next_batch(n_batch)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={input_data: epoch_x, target: epoch_y})\n",
    "            epoch_loss += c\n",
    "\n",
    "        print('Epoch', epoch, 'completed out of',epochs,'loss:',epoch_loss)\n",
    "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(target, 1))\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    print('Accuracy:',accuracy.eval({input_data:mnist.test.images, target:mnist.test.labels}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras or Tensorflow? Why not both?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 2-Alpha\n",
    "\n",
    "Tensorflow 2 is a major update from the Tensforflow team. As quoted from the website, \"TensorFlow 2.0 focuses on simplicity and ease of use, with updates like eager execution, intuitive higher-level APIs, and flexible model building on any platform.\", lets have a look at the implementation from Tensorflow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 6336/60000 [==>...........................] - ETA: 11s - loss: 0.7078 - acc: 0.7972"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-214-b960830623fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1214\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    243\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m     updated = session.run(\n\u001b[0;32m-> 2824\u001b[0;31m         fetches=fetches, feed_dict=feed_dict, **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2825\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## import modules\n",
    "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "#!pip install -q tensorflow==2.0.0-alpha0\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "## load data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of using AI in the field of astronomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning of multi-element abundances from high-resolution spectroscopic data https://arxiv.org/abs/1808.04428\n",
    "\n",
    "\n",
    "Galaxy detection and identification using deep learning and dataaugmentation \n",
    "https://arxiv.org/pdf/1809.01691.pdf\n",
    "\n",
    "CosmoFlow: Using Deep Learning to Learn the Universe at Scale\n",
    "https://arxiv.org/pdf/1808.04728.pdf\n",
    "\n",
    "Identifying Exoplanets with Deep Learning: A Five-planet Resonant Chain around Kepler-80 and an Eighth Planet around Kepler-90\n",
    "https://iopscience.iop.org/article/10.3847/1538-3881/aa9e09/pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Neural Networks?\n",
    "\n",
    "Neural network are very flexible function estimators that learn through being shown \"examples\". Compared to other techniques, a strength of Neural Networks is that they can be customized to fit the structure of a dataset (Convolutional Neural Networks for images, Recurrent Neural Networks for time-series). Another advantage is that once trained, they can yield very quick predictions.\n",
    "\n",
    "Unlike other algorithms like Support Vector Machines or Linear Regression, the loss function they minimize is not convex (ie it does not have a single minimum). Instead it has multiple minimums, and in training we are interested in finding a suitably good minimum (as opposed to a global minimum). This means that their training can sometimes be a lot more fiddly. The loss function that you minimize can also be modified to fit the task you are trying to accomplish (see VAE or GAN for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is actually an interesting debate going on about whether deep learning methods should be assumption driven or whether they should be fully black-box methods. (see this open letter by max welling for example https://staff.fnwi.uva.nl/m.welling/wp-content/uploads/Model-versus-Data-AI-1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This picture shows the loss function with only 2 parameters. As always our intuition breaks down, neural networks will usually have tens of thousands of parameters. A minima will then only occur when all dimenions are at a minimum (otherwise saddle point). As such, its alot harder to reach a local minima. This is the same type of insight as the lottery ticket paper (see link). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
